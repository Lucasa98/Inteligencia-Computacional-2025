{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de997ea6",
   "metadata": {},
   "source": [
    "EJERCICIO 2\n",
    "\n",
    "Mediante el esquema de cinco particiones generadas con KFold, compare el desempeño del perceptrón multicapa con los siguientes clasificadores:\n",
    "\n",
    "* Naive Bayes (GaussianNB)\n",
    "* Análisis discriminante lineal (LDA)\n",
    "* K vecinos más cercanos (KNN)\n",
    "* Arbol de decisión (Decision Tree)\n",
    "* Máquina de soporte vectorial (SVM)\n",
    "\n",
    "Descripción de c/u:\n",
    "\n",
    "* GaussianNB: Calcula la probabilidad de que cada dato pertenezca a cada clase y asigna la clase más probable.\n",
    "\n",
    "* LDA: Calcula una frontera de decisión lineal para clasificar nuevos datos\n",
    "\n",
    "* KNN: Para un dato nuevo, busca sus K vecinos más cercanos en el conjunto de entrenamiento y predice la clase que tenga mayoría entre los vecinos\n",
    "\n",
    "* Decision Tree: Construye un árbol recursivamente donde cada nodo divide respecto de una característica. Las hojas son las clases finales\n",
    "\n",
    "* SVM: Busca un hiperplano que separe las clases maximizando la distancia entre ellas. Puede usar kernels (funciones) para transformar los datos y hacerlos separables en un espacio de mayor dimensión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24efb3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+--------+--------+--------+--------+--------+----------+\n",
      "|  Clasificador | Accuracy Fold 1 | Fold 2 | Fold 3 | Fold 4 | Fold 5 | Media  | Varianza |\n",
      "+---------------+-----------------+--------+--------+--------+--------+--------+----------+\n",
      "|      MLP      |      0.9694     | 0.9722 | 0.9721 | 0.9749 | 0.9582 | 0.9694 | 0.000034 |\n",
      "|  Naive Bayes  |      0.8472     | 0.8472 | 0.8022 | 0.8579 | 0.8412 | 0.8392 | 0.000370 |\n",
      "|      LDA      |      0.9444     | 0.9750 | 0.9387 | 0.9666 | 0.9359 | 0.9521 | 0.000247 |\n",
      "|      KNN      |      0.9861     | 0.9944 | 0.9721 | 0.9944 | 0.9833 | 0.9861 | 0.000068 |\n",
      "| Decision Tree |      0.8417     | 0.8750 | 0.8524 | 0.8524 | 0.8635 | 0.8570 | 0.000129 |\n",
      "|      SVM      |      0.9778     | 0.9778 | 0.9721 | 0.9777 | 0.9694 | 0.9750 | 0.000013 |\n",
      "+---------------+-----------------+--------+--------+--------+--------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# ========================\n",
    "# Cargar dataset\n",
    "# ========================\n",
    "\n",
    "digits = load_digits()\n",
    "x=digits.data\n",
    "y=digits.target \n",
    "\n",
    "# ========================\n",
    "# Definir clasificadores\n",
    "# ========================\n",
    "\n",
    "classifiers = {\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42)\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# KFold 5 splits\n",
    "# ========================\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    accuracies = []\n",
    "    for trn_idx, tst_idx in kf.split(x):\n",
    "        x_trn, x_tst = x[trn_idx], x[tst_idx]\n",
    "        y_trn, y_tst = y[trn_idx], y[tst_idx]\n",
    "        \n",
    "        clf.fit(x_trn, y_trn)\n",
    "        y_pred = clf.predict(x_tst)\n",
    "        acc = accuracy_score(y_tst, y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    var_acc = np.var(accuracies)\n",
    "    results[name] = (accuracies, mean_acc, var_acc)\n",
    "\n",
    "\n",
    "# ========================\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Clasificador\", \"Accuracy Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Fold 5\", \"Media\", \"Varianza\"]\n",
    "\n",
    "for name, (accs, mean_acc, var_acc) in results.items():\n",
    "    table.add_row([name, *[f\"{a:.4f}\" for a in accs], f\"{mean_acc:.4f}\", f\"{var_acc:.6f}\"])\n",
    "\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
